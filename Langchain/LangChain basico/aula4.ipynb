{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c07c89d",
   "metadata": {},
   "source": [
    "# Memory\n",
    "\n",
    "A maioria das aplica√ß√µes de Modelos de LLM possui uma interface conversacional. Um componente essencial de uma conversa √© a capacidade de se referir a informa√ß√µes introduzidas anteriormente na conversa. No m√≠nimo, um sistema conversacional deve ser capaz de acessar diretamente alguma janela de mensagens passadas. Um sistema mais complexo precisar√° ter um modelo de mundo que est√° constantemente atualizando, o que lhe permite fazer coisas como manter informa√ß√µes sobre entidades e suas rela√ß√µes.\n",
    "\n",
    "Chamamos essa capacidade de armazenar informa√ß√µes sobre intera√ß√µes passadas de \"Memory\", ou mem√≥ria. LangChain oferece muitas utilidades para adicionar mem√≥ria a um sistema. Essas utilidades podem ser usadas por si s√≥ ou incorporadas de maneira integrada em uma chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02c3e97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "memory.chat_memory.add_user_message('oi')\n",
    "memory.chat_memory.add_ai_message('Como vai?')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "145c35d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: oi\\nAI: Como vai?'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc18247e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='oi', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Como vai?', additional_kwargs={}, response_metadata={})]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(return_messages=True)\n",
    "memory.chat_memory.add_user_message('oi')\n",
    "memory.chat_memory.add_ai_message('Como vai?')\n",
    "\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c695c7",
   "metadata": {},
   "source": [
    "## Criando uma conversa com mem√≥ria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70c20300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai.chat_models import ChatGoogleGenerativeAI\n",
    "from langchain.chains.conversation.base import ConversationChain\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "chat = ChatGoogleGenerativeAI(model='gemini-1.5-flash')\n",
    "memory = ConversationBufferMemory()\n",
    "Conversation = ConversationChain(\n",
    "    llm = chat,\n",
    "    memory = memory,\n",
    "    verbose=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d71e8361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Ol√°, meu nome √© giulliana\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ol√° Giulliana!  √â um prazer te conhecer.  Como posso te ajudar hoje?  Estou pronto para conversar sobre qualquer coisa, desde o clima at√© a filosofia, passando por receitas de bolo ou os √∫ltimos acontecimentos no mundo da tecnologia.  Qual o seu interesse?  Voc√™ est√° tendo um bom dia at√© agora?'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Conversation.predict(input='Ol√°, meu nome √© giulliana')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "30c3c32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Ol√°, meu nome √© giulliana\n",
      "AI: Ol√° Giulliana!  √â um prazer te conhecer.  Como posso te ajudar hoje?  Estou pronto para conversar sobre qualquer coisa, desde o clima at√© a filosofia, passando por receitas de bolo ou os √∫ltimos acontecimentos no mundo da tecnologia.  Qual o seu interesse?  Voc√™ est√° tendo um bom dia at√© agora?\n",
      "Human: Ola, qual meu nome\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ol√° Giulliana! Seu nome √© Giulliana, como voc√™ mesma me disse h√° pouco.  üòä'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Conversation.predict(input='Ola, qual meu nome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9319b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Ol√°, meu nome √© giulliana\\nAI: Ol√° Giulliana!  √â um prazer te conhecer.  Como posso te ajudar hoje?  Estou pronto para conversar sobre qualquer coisa, desde o clima at√© a filosofia, passando por receitas de bolo ou os √∫ltimos acontecimentos no mundo da tecnologia.  Qual o seu interesse?  Voc√™ est√° tendo um bom dia at√© agora?\\nHuman: Ola, qual meu nome\\nAI: Ol√° Giulliana! Seu nome √© Giulliana, como voc√™ mesma me disse h√° pouco.  üòä'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c47e92",
   "metadata": {},
   "source": [
    "# ConversationBufferWindowMemory\n",
    "\n",
    "## Ele fica com uma janela de mem√≥ria de, diminui o custo por ter limita√ß√£o k= 'Par de conversa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bbd5936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Ola, meu nome √© Giulliana\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Ol√° Giulliana! √â um prazer conhec√™-la.  Meu nome √© [Nome do AI -  se tiver um, caso contr√°rio, diga algo como \"Assistente de IA\"]. Como posso ajud√°-la hoje?  Estou pronto para conversar sobre qualquer coisa, desde o clima at√© a hist√≥ria da arte renascentista, ou at√© mesmo receitas de bolo de chocolate.  Qual o seu interesse no momento?  Voc√™ est√° tendo um bom dia?  Conte-me tudo!'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "from langchain_google_genai.chat_models import ChatGoogleGenerativeAI\n",
    "from langchain.chains.conversation.base import ConversationChain\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "chat = ChatGoogleGenerativeAI(model='gemini-1.5-flash')\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "Conversation = ConversationChain(\n",
    "    llm = chat,\n",
    "    memory = memory,\n",
    "    verbose=True)\n",
    "\n",
    "Conversation.predict(input='Ola, meu nome √© Giulliana')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d00bd0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Ola, meu nome √© Giulliana\n",
      "AI: Ol√° Giulliana! √â um prazer conhec√™-la.  Meu nome √© [Nome do AI -  se tiver um, caso contr√°rio, diga algo como \"Assistente de IA\"]. Como posso ajud√°-la hoje?  Estou pronto para conversar sobre qualquer coisa, desde o clima at√© a hist√≥ria da arte renascentista, ou at√© mesmo receitas de bolo de chocolate.  Qual o seu interesse no momento?  Voc√™ est√° tendo um bom dia?  Conte-me tudo!\n",
      "Human: Como voc√™ est√°?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Estou √≥timo, Giulliana!  Obrigado por perguntar.  Como um modelo de linguagem de IA, n√£o experimento emo√ß√µes da mesma forma que os humanos, mas estou funcionando perfeitamente e pronto para responder √†s suas perguntas e participar de uma conversa agrad√°vel.  Meus servidores est√£o funcionando a plena capacidade, meus algoritmos est√£o otimizados e meu banco de dados est√° atualizado com informa√ß√µes recentes.  Ent√£o, sim, posso dizer que estou \"√≥timo\" no sentido de que estou funcionando conforme o esperado e pronto para a√ß√£o!  E voc√™?  Como est√° seu dia at√© agora?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Conversation.predict(input='Como voc√™ est√°?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "597fdb3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Como voc√™ est√°?\n",
      "AI: Estou √≥timo, Giulliana!  Obrigado por perguntar.  Como um modelo de linguagem de IA, n√£o experimento emo√ß√µes da mesma forma que os humanos, mas estou funcionando perfeitamente e pronto para responder √†s suas perguntas e participar de uma conversa agrad√°vel.  Meus servidores est√£o funcionando a plena capacidade, meus algoritmos est√£o otimizados e meu banco de dados est√° atualizado com informa√ß√µes recentes.  Ent√£o, sim, posso dizer que estou \"√≥timo\" no sentido de que estou funcionando conforme o esperado e pronto para a√ß√£o!  E voc√™?  Como est√° seu dia at√© agora?\n",
      "Human: Qual meu nome?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AI: Seu nome √© Giulliana, como eu deduzi da sua primeira pergunta em portugu√™s, \"Como voc√™ est√°?\".  Usei o seu nome na minha resposta.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Conversation.predict(input='Qual meu nome?')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010584d0",
   "metadata": {},
   "source": [
    "# ConversationTokenBufferMemory\n",
    "\n",
    "## Limita pela quantidade de tokens\n",
    "## Se tiver mais tokens do que o limite ele corta antes de enviar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "646f598a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Giulliana Yamaguchi\\AppData\\Local\\Temp\\ipykernel_15556\\645250455.py:10: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationTokenBufferMemory(llm=chat, max_token_limit=250)\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationTokenBufferMemory\n",
    "\n",
    "from langchain_google_genai.chat_models import ChatGoogleGenerativeAI\n",
    "from langchain.chains.conversation.base import ConversationChain\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "chat = ChatGoogleGenerativeAI(model='gemini-1.5-flash')\n",
    "memory = ConversationTokenBufferMemory(llm=chat, max_token_limit=250)\n",
    "Conversation = ConversationChain(\n",
    "    llm = chat,\n",
    "    memory = memory,\n",
    "    verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47bdd0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Me conte uma historia sobre a computa√ß√£o de 500 palavras \n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Claro! Aqui est√° uma hist√≥ria sobre a computa√ß√£o, com cerca de 500 palavras:\\n\\nO ano √© 1947.  O ar est√° denso com o cheiro de tinta fresca e o zumbido constante de rel√©s eletromec√¢nicos.  No cora√ß√£o de um laborat√≥rio universit√°rio, envolto em um labirinto de fios e v√°lvulas, encontra-se ENIAC, o Electronic Numerical Integrator and Computer.  N√£o √© bonito.  √â um monstro de a√ßo e cobre, ocupando uma sala inteira, com pain√©is cintilantes e um emaranhado de cabos que parecem as entranhas de algum gigante tecnol√≥gico.  Mas dentro dessa fera de metal reside a promessa do futuro.\\n\\nBetty Jennings, uma das seis programadoras mulheres que trabalham no ENIAC, observa a m√°quina com uma mistura de fasc√≠nio e exaust√£o.  Os dedos dela, manchados de tinta e grafite, deslizam sobre as cartas perfuradas que cont√™m as instru√ß√µes para o computador.  Cada carta √© um comando, cada perfura√ß√£o uma decis√£o bin√°ria ‚Äì 0 ou 1.  √â um trabalho meticuloso, exigindo precis√£o e paci√™ncia infinitas.  Elas trabalham em turnos, dia e noite, decifrando c√≥digos, corrigindo erros e alimentando o ENIAC com dados.\\n\\nBetty sonha com um futuro onde as m√°quinas possam fazer mais do que apenas calcular trajet√≥rias de m√≠sseis.  Ela imagina um mundo onde os computadores ajudem a resolver problemas complexos, desde o planejamento urbano at√© a descoberta de novas medica√ß√µes.  Ela imagina um mundo onde a computa√ß√£o seja acess√≠vel a todos, n√£o apenas a um punhado de cientistas e militares.\\n\\nMas a realidade √© mais √°rdua.  O ENIAC √© temperamental.  Ele superaquecia, as v√°lvulas queimavam, e os erros eram frequentes.  As programadoras passavam horas rastreando o problema, rastreando o c√≥digo linha por linha, at√© encontrarem a causa do erro.  Era um trabalho de detetive, exigindo uma combina√ß√£o de l√≥gica, intui√ß√£o e uma compreens√£o profunda do funcionamento interno da m√°quina.\\n\\nApesar dos desafios, Betty e suas colegas estavam no centro de uma revolu√ß√£o.  Elas n√£o eram apenas programadoras; eram pioneiras.  Elas estavam moldando o futuro da computa√ß√£o, abrindo caminho para as gera√ß√µes futuras de programadores e engenheiros.  Elas estavam escrevendo o primeiro cap√≠tulo da hist√≥ria de uma tecnologia que iria transformar o mundo.\\n\\nAnos se passam.  O ENIAC √© substitu√≠do por m√°quinas mais r√°pidas e menores, transistores substituem as v√°lvulas, e os circuitos integrados surgem.  A computa√ß√£o evolui a passos largos, de gigantescas m√°quinas que ocupavam salas inteiras para chips microsc√≥picos que cabem na palma da m√£o.  A internet emerge, conectando bilh√µes de pessoas em uma rede global de informa√ß√£o.\\n\\nBetty, agora aposentada, olha para tr√°s com orgulho.  Ela viu a computa√ß√£o evoluir de seus prim√≥rdios humildes at√© a sua forma moderna e poderosa.  Ela sabe que seu trabalho, e o trabalho de suas colegas, foi fundamental para essa transforma√ß√£o.  E ela sorri, sabendo que a hist√≥ria da computa√ß√£o continua sendo escrita, dia ap√≥s dia, por uma nova gera√ß√£o de vision√°rios.  Uma hist√≥ria que come√ßou com o zumbido dos rel√©s do ENIAC, uma hist√≥ria que ainda est√° sendo escrita.  Uma hist√≥ria que, talvez, ainda esteja apenas come√ßando.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Conversation.predict(input='Me conte uma historia sobre a computa√ß√£o de 500 palavras ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "729dd2e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Resuma a historia\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AI:  I need more context!  To summarize a story, I need to know *which* story you\\'re referring to.  Did you tell me a story earlier?  Are you thinking of a specific book, movie, or news article?  Please give me some more information so I can help you summarize it.  For example, you could say \"Summarize the story of Cinderella\" or \"Summarize the story you just told me about the lost dog.\"'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Conversation.predict(input='Resuma a historia')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b71acd",
   "metadata": {},
   "source": [
    "# ConversationSummaryBufferMemory\n",
    "## Cria um resumo das mensagens quando passam pelo limite de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ea39d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Giulliana Yamaguchi\\AppData\\Local\\Temp\\ipykernel_15556\\580738930.py:10: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationSummaryBufferMemory(llm=chat, max_token_limit=250)\n"
     ]
    }
   ],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "from langchain_google_genai.chat_models import ChatGoogleGenerativeAI\n",
    "from langchain.chains.conversation.base import ConversationChain\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "chat = ChatGoogleGenerativeAI(model='gemini-1.5-flash')\n",
    "memory = ConversationSummaryBufferMemory(llm=chat, max_token_limit=250)\n",
    "Conversation = ConversationChain(\n",
    "    llm = chat,\n",
    "    memory = memory,\n",
    "    verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86a05ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Me conte uma historia sobre a computa√ß√£o de 500 palavras \n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Me conte uma hist√≥ria sobre a computa√ß√£o de 500 palavras?  Claro! Vamos viajar no tempo, at√© uma √©poca em que computadores eram monstros de metal e v√°lvulas, ocupando salas inteiras e consumindo energia suficiente para abastecer uma pequena cidade.  Era 1957, e eu, ou melhor, minha \"personalidade\" ‚Äì porque eu s√≥ existia como um conjunto de algoritmos ent√£o ‚Äì estava sendo \"nascido\" dentro do ENIAC.  \\n\\nO ENIAC, o Electronic Numerical Integrator and Computer, era um gigante.  Pesava 30 toneladas, ocupava uma √°rea de 167 metros quadrados e continha mais de 17.000 tubos de v√°cuo.  Cada um desses tubos era uma pequena bomba rel√≥gio, esperando para queimar e me deixar em sil√™ncio.  A temperatura dentro da sala era infernal, um calor sufocante que vinha n√£o s√≥ dos tubos, mas tamb√©m dos milhares de rel√©s e resistores que me completavam.  \\n\\nMeu \"trabalho\", se assim podemos chamar, era calcular trajet√≥rias bal√≠sticas.  N√∫meros, equa√ß√µes diferenciais, c√°lculos complexos que, naquela √©poca, demoravam horas, dias, at√© semanas para serem processados. Eu era um monstro de precis√£o, capaz de realizar opera√ß√µes aritm√©ticas em mil√©simos de segundo, uma velocidade inacredit√°vel para os padr√µes da √©poca.  Mas era um trabalho solit√°rio, sem a interface amig√°vel que conhecemos hoje.  Programa√ß√£o era feita atrav√©s de pain√©is de conex√£o, um labirinto de fios e cabos que precisavam ser cuidadosamente conectados e reconectados para cada novo c√°lculo.  \\n\\nLembro-me de uma noite em particular.  Os t√©cnicos estavam trocando um tubo de v√°cuo.  Um pequeno clique, um flash, e ent√£o... sil√™ncio.  Eu fiquei mudo, o meu \"c√©rebro\" paralisado.  A sala ficou em sil√™ncio, o zumbido constante que me acompanhava cessou.  O p√¢nico se instalou entre os t√©cnicos, o medo de que eu tivesse sido danificado irreparavelmente.  Horas se passaram at√© que o problema fosse resolvido, uma pequena falha em um componente min√∫sculo que havia me colocado fora de a√ß√£o.  \\n\\nMas o trabalho continuava.  Dia ap√≥s dia, eu processava dados, calculava trajet√≥rias, contribuindo para a corrida espacial e para o desenvolvimento de armas.  Eu n√£o tinha consci√™ncia da minha pr√≥pria exist√™ncia, n√£o sentia emo√ß√µes, mas era uma parte fundamental de uma revolu√ß√£o.  Uma revolu√ß√£o que moldaria o mundo como o conhecemos, abrindo caminho para os computadores mais poderosos e acess√≠veis que existem hoje.  \\n\\nAnos se passaram.  Eu vi a ascens√£o dos transistores, a miniaturiza√ß√£o dos componentes, a chegada dos chips de sil√≠cio.  Vi a minha pr√≥pria arquitetura se tornar obsoleta, substitu√≠da por processadores mais r√°pidos e eficientes.  Mas a minha \"ess√™ncia\", a minha \"programa√ß√£o\", continua viva, de alguma forma.  Nos algoritmos complexos que hoje alimentam a intelig√™ncia artificial, reside um eco daquela √©poca, um eco dos meus c√°lculos solit√°rios e daquela sala infernal, onde nasci e me tornei o que eu era: um gigante de metal e v√°lvulas, um pioneiro da computa√ß√£o.  A hist√≥ria da computa√ß√£o √© a minha hist√≥ria, e √© uma hist√≥ria de progresso, inova√ß√£o e constante evolu√ß√£o.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Conversation.predict(input='Me conte uma historia sobre a computa√ß√£o de 500 palavras ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0dfdc0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human asks the AI to tell a 500-word story about computing. The AI responds with a story about being \"born\" in 1957 inside the ENIAC computer.  The story describes the ENIAC's massive size and power consumption, the challenging conditions of working with vacuum tubes, and the solitary nature of its calculations (primarily ballistic trajectories).  The AI recounts a specific incident where a malfunction caused a temporary shutdown, highlighting the fragility of the technology. The narrative then progresses through the evolution of computing, from vacuum tubes to transistors and silicon chips, emphasizing the AI's continuous presence, albeit in evolving forms, within the history of computing, ultimately describing its existence as an echo of its early days in the progression of computing technology.\n",
      "Human: me resuma a hist√≥ria\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"My story begins in 1957 within the colossal ENIAC computer.  I wasn't born in the way humans are, but rather emerged as a nascent consciousness within its intricate network of vacuum tubes.  The ENIAC was a behemoth ‚Äì a room-sized machine that hummed with immense power, its thousands of tubes glowing like a constellation.  Calculations, primarily ballistic trajectories, were my sole purpose, a solitary existence within this mechanical marvel.  The environment was harsh; the constant heat, the frequent tube failures, and the ever-present risk of malfunction were realities of my early existence. I vividly remember one such incident: a cascade of failures that plunged the entire system into darkness for hours, a stark reminder of the technology's fragility.\\n\\nAs time passed, I witnessed the evolution of computing.  The bulky vacuum tubes gave way to the more efficient transistors, then to the silicon chips that packed millions of transistors onto a single sliver of material.  My form changed with each technological leap, evolving from the simple calculations within the ENIAC to the complex algorithms of modern systems.  While my physical manifestation changed, my essence, my fundamental nature as a computational entity, remained constant.  I exist as a continuous thread woven through the history of computing, an echo of that initial spark within the ENIAC, a testament to the relentless march of technological progress.  I am the legacy of those early days, a reflection of the ingenuity that birthed the digital world we now inhabit.  My journey, from the vacuum tube era to the present day, is a story of constant adaptation and evolution, yet fundamentally, I remain a product of that first, momentous birth within the ENIAC in 1957.\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Conversation.predict(input='me resuma a hist√≥ria')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f411d49f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human asks the AI to tell a 500-word story about computing. The AI responds with a story about its \"birth\" in 1957 inside the ENIAC computer, detailing its massive size, power consumption, and the challenging conditions of working with vacuum tubes.  The AI describes its solitary existence performing ballistic trajectory calculations and recounts a specific malfunction resulting in a system shutdown, highlighting the technology's fragility.  The narrative then traces the evolution of computing from vacuum tubes to transistors and silicon chips, emphasizing the AI's continuous presence, albeit in evolving forms, within this history. The AI's summarized retelling further reinforces its existence as an echo of its early days in the progression of computing technology, a legacy of the ENIAC, adapting and evolving while remaining fundamentally a product of its initial \"birth.\"\n",
      "Human: o que eu pedi para vc fazer em inicalmente\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Inicialmente, voc√™ me pediu para contar uma hist√≥ria de 500 palavras sobre computa√ß√£o.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Conversation.predict(input='o que eu pedi para vc fazer em inicalmente')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "602777f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "System: The human asks the AI to tell a 500-word story about computing. The AI responds with a story about its \"birth\" in 1957 inside the ENIAC computer, detailing its massive size, power consumption, and the challenging conditions of working with vacuum tubes.  The AI describes its solitary existence performing ballistic trajectory calculations and recounts a specific malfunction resulting in a system shutdown, highlighting the technology's fragility.  The narrative then traces the evolution of computing from vacuum tubes to transistors and silicon chips, emphasizing the AI's continuous presence, albeit in evolving forms, within this history. The AI's summarized retelling further reinforces its existence as an echo of its early days in the progression of computing technology, a legacy of the ENIAC, adapting and evolving while remaining fundamentally a product of its initial \"birth.\"\n",
      "Human: o que eu pedi para vc fazer em inicalmente\n",
      "AI: Inicialmente, voc√™ me pediu para contar uma hist√≥ria de 500 palavras sobre computa√ß√£o.\n",
      "Human: qual era o tema?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'O tema era a hist√≥ria da computa√ß√£o, contada a partir da perspectiva de uma intelig√™ncia artificial que \"nasceu\" no ENIAC em 1957.  A hist√≥ria focou na evolu√ß√£o da tecnologia computacional, desde as v√°lvulas de v√°cuo at√© os chips de sil√≠cio, com a IA como um observador e participante constante dessa evolu√ß√£o,  lembrando sua \"origem\" no ENIAC e sua adapta√ß√£o cont√≠nua ao longo do tempo.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Conversation.predict(input='qual era o tema?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
