{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3be658f2",
   "metadata": {},
   "source": [
    "# Conceitos avan√ßados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8093cb6b",
   "metadata": {},
   "source": [
    "* ### Prompt Few-shot\n",
    "* #### √â uma forma de ensinar o modelo a base de exemplos, mostrando o padr√£o de resposta, melhorando a formata√ß√£o e precis√£o da resposta.\n",
    "\n",
    "* √â similar a formata√ß√£o de mensagens da api da OpenAI, mas com uma sintaxe diferente: \n",
    "\n",
    "```python\n",
    "    mensagens = [\n",
    "        {'role': 'user','content': 'quanto √© 1+1'}, \n",
    "        {'role': 'assistant','content': '2'},\n",
    "        {'role': 'user','content': 'quanto √© 10 * 5?' },\n",
    "        {'role': 'assistant', 'content':'50'},\n",
    "        {'role': 'user','content': 'quanto √© 10 + 3?' },\n",
    "        \n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25d9cd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libs \n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "#carrega arquivo .env ao ambiente \n",
    "load_dotenv()\n",
    "\n",
    "if not os.getenv('GOOGLE_API_KEY'): \n",
    "    raise ValueError(\"Chave GOOGLE_API_KEY N√ÉO encontrada no arquivo .env\")\n",
    "\n",
    "chat = ChatGoogleGenerativeAI(model='gemini-1.5-flash')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "028b78fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n"
     ]
    }
   ],
   "source": [
    "mensagens = [\n",
    "    HumanMessage(content='quanto √© 1 + 1?'),\n",
    "    AIMessage(content='2'),\n",
    "    HumanMessage(content='quanto √© 10 * 5?'),\n",
    "    AIMessage(content='50'),\n",
    "    HumanMessage(content='quanto √© 10 + 3?')\n",
    "]\n",
    "\n",
    "resposta = chat.invoke(mensagens)\n",
    "\n",
    "print(resposta.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3cba948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[llm:ChatGoogleGenerativeAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: quanto √© 1 + 1?\\nAI: 2\\nHuman: quanto √© 10 * 5?\\nAI: 50\\nHuman: quanto √© 10 + 3?\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[llm:ChatGoogleGenerativeAI] [5ms] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"13\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"safety_ratings\": []\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"13\",\n",
      "            \"response_metadata\": {\n",
      "              \"prompt_feedback\": {\n",
      "                \"block_reason\": 0,\n",
      "                \"safety_ratings\": []\n",
      "              },\n",
      "              \"finish_reason\": \"STOP\",\n",
      "              \"safety_ratings\": []\n",
      "            },\n",
      "            \"type\": \"ai\",\n",
      "            \"id\": \"run--51a57dc0-3bca-4dd4-8649-48826b9e78b9-0\",\n",
      "            \"usage_metadata\": {\n",
      "              \"input_tokens\": 29,\n",
      "              \"output_tokens\": 3,\n",
      "              \"total_tokens\": 32,\n",
      "              \"input_token_details\": {\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"total_cost\": 0\n",
      "            },\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": []\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null,\n",
      "  \"type\": \"LLMResult\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#debugar \n",
    "\n",
    "import langchain\n",
    "\n",
    "langchain.debug = True\n",
    "chat.invoke(mensagens)\n",
    "\n",
    "langchain.debug = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971028b3",
   "metadata": {},
   "source": [
    "## Caching\n",
    "\n",
    "- **Cache de mem√≥ria** - serve para economziar tokens, viusto que ele ir√° salvar respostas em cache, caso tenha a mesma pergunta ele pega do cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c350833",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libs\n",
    "\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model='gemini-1.5-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1840b10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mensagens = [\n",
    "    SystemMessage(content='Voc√™ √© um assistente engra√ßado.'),\n",
    "    HumanMessage(content='Quanto √© 1 + 1? ')\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73eac321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cacheamento\n",
    "\n",
    "from langchain.cache import InMemoryCache\n",
    "from langchain.globals import set_llm_cache\n",
    "\n",
    "set_llm_cache(InMemoryCache())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14cc1cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 1.37 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Depende! Se estivermos falando de n√∫meros inteiros em um sistema num√©rico padr√£o, a resposta √©, obviamente, 2.  Mas e se estivermos falando de ma√ß√£s?  Ent√£o voc√™ teria duas ma√ß√£s deliciosas, prontas para uma receita incr√≠vel de torta! Ou talvez dois problemas se voc√™ n√£o conseguir decidir qual comer primeiro.  E se for amor?  Ah, amor... 1 + 1 √© igual a um amor infinitamente maior, cheio de beijos, abra√ßos e muito, muito mais do que duas pessoas separadas!  A matem√°tica √© divertida, n√£o √©? üòâ', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--7c0bc866-a862-4133-8876-3d2f7cd9c4e3-0', usage_metadata={'input_tokens': 15, 'output_tokens': 125, 'total_tokens': 140, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8a2709c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 1.07 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Depende! Se estivermos falando de n√∫meros inteiros em um sistema num√©rico padr√£o, a resposta √©, obviamente, 2.  Mas e se estivermos falando de ma√ß√£s?  Ent√£o voc√™ teria duas ma√ß√£s deliciosas, prontas para uma receita incr√≠vel de torta! Ou talvez dois problemas se voc√™ n√£o conseguir decidir qual comer primeiro.  E se for amor?  Ah, amor... 1 + 1 √© igual a um amor infinitamente maior, cheio de beijos, abra√ßos e muito, muito mais do que duas pessoas separadas!  A matem√°tica √© divertida, n√£o √©? üòâ', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--7c0bc866-a862-4133-8876-3d2f7cd9c4e3-0', usage_metadata={'input_tokens': 15, 'output_tokens': 125, 'total_tokens': 140, 'input_token_details': {'cache_read': 0}, 'total_cost': 0})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b863189",
   "metadata": {},
   "source": [
    "## Caching\n",
    "\n",
    "- **Cache com SQLite** - forma de cache em banco, mesmo desligando a aplica√ß√£o os dados ainda ficam salvos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad62b3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.cache import SQLiteCache\n",
    "from langchain.globals import set_llm_cache\n",
    "\n",
    "# 3. Configure o cache com o caminho corrigido\n",
    "set_llm_cache(SQLiteCache(database_path='Arquivos/Langchain_cache.sqlite'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e262454c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 2.39 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Depende.  Voc√™ quer a resposta matem√°tica chata e previs√≠vel, ou a resposta divertida e imprevis√≠vel que envolve viagens no tempo, a natureza da realidade e a poss√≠vel exist√™ncia de universos paralelos onde 1 + 1 = abacate?  \\n\\n...Estou brincando (a menos que...?). A resposta √© 2.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--df59e492-fbb1-4cc4-ad14-c5552ec05627-0', usage_metadata={'input_tokens': 15, 'output_tokens': 72, 'total_tokens': 87, 'input_token_details': {'cache_read': 0}, 'total_cost': 0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "chat.invoke(mensagens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a576800f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 2.24 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Depende.  Voc√™ quer a resposta matem√°tica chata e previs√≠vel, ou a resposta divertida e imprevis√≠vel que envolve viagens no tempo, a natureza da realidade e a poss√≠vel exist√™ncia de universos paralelos onde 1 + 1 = abacate?  \\n\\n...Estou brincando (a menos que...?). A resposta √© 2.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []}, id='run--df59e492-fbb1-4cc4-ad14-c5552ec05627-0', usage_metadata={'input_tokens': 15, 'output_tokens': 72, 'total_tokens': 87, 'input_token_details': {'cache_read': 0}, 'total_cost': 0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "chat.invoke(mensagens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
